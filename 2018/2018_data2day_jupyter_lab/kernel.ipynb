{
  "cells": [
    {
      "metadata": {
        "_uuid": "aaeb53c16fe914963fc0baa1d5ad411652356bfe"
      },
      "cell_type": "markdown",
      "source": "# New York City Taxi Fare Prediction Playground Competition\n\nThis is my notebook I used to explore the NYC Taxi Fare dataset. Use this yourself to explore the dataset. If you have question, sent me a message!\n\nHave fun!\n\nAlbert van Breemen\n27/7/2018\n\n**Update**\n\n2018/08/27\n- Corrected error in calculating min/max coordinates. This error has no consequence for the remaining analysis. [Thanks to Pegah]\n\n2018/08/10\n- Added visuals to analyse the importance of the direction of a trip\n\n2018/08/08\n- Using the insights from this notebook, I trained a model that got a #1 position on 2018/08/07 (LB score 2.88396)\n- Added pickup traffic density plots to see how busy it is in Manhatten by the hour\n\n2018/08/04\n- Thanks for all the feedback! This notebook is becoming rather long, but there is so much fun stuff to analyse!! ;)\n- updated the boundingbox and NYC maps, as one test point was not within the bounding box\n- added zoomed in map of NYC\n- added hiresolution NYC/Manhattan map plot\n- added function to remove datapoints from water\n- small update in datapoints per sq miles calculation\n\n2018/07/30\n- Corrected 'ewr'/'lgr' typo [Thanks to Lu Mingming]\n- Small update `plot_on_map` function\n- Converted distances to miles [Thanks to sandy1112]\n- Add Taxi pricing rules [Thanks to sandy1112]\n- Added density plots (datapoints per sq mile)\n\n2018/07/28 \n- Added a graph with estimated drive time for two trips using Google Map Traffic info. This could explain how fare depends on hour of the day.\n\n\n## Reading data and first exploration\n\n\nFirst thing I like to do with a new dataset is to explore the data. This means investigating the number of features, their datatype, their meaning and statistics."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9644171fd7294391b887803d35c1bd565eb577b5"
      },
      "cell_type": "code",
      "source": "# load some default Python modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n% matplotlib inline\nplt.style.use('seaborn-whitegrid')",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f9d8f4c2679ce2ac3a4ea114b3cb12b2e66f091d"
      },
      "cell_type": "markdown",
      "source": "As this dataset is huge reading all data would require a lot of memory. Therefore I read a limited number of rows while exploring the data. When my exploration code (e.g. this notebook) is ready I re-run the notebook while reading more rows."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "45366fe52f68cc504422248cdf5bac4b0b526c6b"
      },
      "cell_type": "code",
      "source": "# read data in pandas dataframe\ndf_train =  pd.read_csv('../input/train.csv', nrows = 2_000_000, parse_dates=[\"pickup_datetime\"])\n\n# list first few rows (datapoints)\ndf_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c221cfee76464d443e6ac2817dd2ae4d1c5e8774"
      },
      "cell_type": "code",
      "source": "# check datatypes\ndf_train.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b663e58b73665c6df9c48d215b54ee9d46ff58f4"
      },
      "cell_type": "code",
      "source": "# check statistics of the features\ndf_train.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "154670900c260932248ad2594bbbfd945802c244"
      },
      "cell_type": "markdown",
      "source": "The following things I notice (while using 500k datapoints):\n\n- The minimal `fare_amount` is negative. As this does not seem to be realistic I will drop them from the dataset.\n- Some of the minimum and maximum longitude/lattitude coordinates are way off. These I will also remove from the dataset (I will define a bounding box for the coordinates, see further).\n- The average `fare_amount` is about \\$11.4 USD with a standard deviation of \\$9.9 USD. When building a predictive model we want to be better than $9.9 USD :)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28e75eac860d266b6a562e8dac711e392f73ad26"
      },
      "cell_type": "code",
      "source": "print('Old size: %d' % len(df_train))\ndf_train = df_train[df_train.fare_amount>=0]\nprint('New size: %d' % len(df_train))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e01144533c5dfaecffae2b2949982f889f0671c6"
      },
      "cell_type": "code",
      "source": "# plot histogram of fare\ndf_train[df_train.fare_amount<100].fare_amount.hist(bins=100, figsize=(14,3))\nplt.xlabel('fare $USD')\nplt.title('Histogram');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fe0ae2fdcdc14b393adb911ea349df786317f069"
      },
      "cell_type": "markdown",
      "source": "In the histogram of the `fare_amount` there are some small spikes between \\$40 and \\$60. This could indicate some fixed fare price (e.g. to/from airport). This will be explored further below."
    },
    {
      "metadata": {
        "_uuid": "ae7feba8a8607ccfbfb5f6c006e67786ec026103"
      },
      "cell_type": "markdown",
      "source": "## Remove missing data\n\nAlways check to see if there is missing data. As this dataset is huge, removing datapoints with missing data probably has no effect on the models beings trained."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d6afce44ae49df0b97d6f00a8b60999128e06af9"
      },
      "cell_type": "code",
      "source": "print(df_train.isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c96988b66b5e3cd76ad3da35e4338882ef09880"
      },
      "cell_type": "code",
      "source": "print('Old size: %d' % len(df_train))\ndf_train = df_train.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(df_train))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c52e972ae6d4035b097352debfec0e061975e13b"
      },
      "cell_type": "markdown",
      "source": "## Test data\nRead the test data to check the statistics and compare with the training set."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a5e9332123bfef0ffbe8ed646f0d75240c48b90"
      },
      "cell_type": "code",
      "source": "# read data in pandas dataframe\ndf_test =  pd.read_csv('../input/test.csv')\ndf_test.head(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2deedc5069ca226c34f31550fe8af62bd8b9a724"
      },
      "cell_type": "code",
      "source": "df_test.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b95cbb5d39b46bf4e82d9736cdf5b2cff2d59275"
      },
      "cell_type": "markdown",
      "source": "## Location data\n\nAs we're dealing with location data, I want to plot the coordinates on a map. This gives a better view of the data. For this, I use the following website:\n\n- Easy to use map and GPS tool: https://www.gps-coordinates.net/ \n- Calculate distance between locations: https://www.travelmath.com/flying-distance/\n- Open street map to grab using bouding box a map: https://www.openstreetmap.org/export#map=8/52.154/5.295\n\nNew York city coordinates are (https://www.travelmath.com/cities/New+York,+NY):\n\n- longitude = -74.0063889\n- lattitude = 40.7141667\n\nI define a bounding box of interest by [long_min, long_max, latt_min, latt_max] using the minimum and maximum coordinates from the testset. This way, I'm sure to train a model for the full pickup/dropoff coordinate range of the test set.\n\nFrom Open Street Map I grab a map and I drop any datapoint outside this box."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c17ad8ee3546ec2919a7effed1299f6eedcd845f"
      },
      "cell_type": "code",
      "source": "# minimum and maximum longitude test set\nmin(df_test.pickup_longitude.min(), df_test.dropoff_longitude.min()), \\\nmax(df_test.pickup_longitude.max(), df_test.dropoff_longitude.max())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6030e9ba9a2937d9898b3991f2bb466730613610"
      },
      "cell_type": "code",
      "source": "# minimum and maximum latitude test\nmin(df_test.pickup_latitude.min(), df_test.dropoff_latitude.min()), \\\nmax(df_test.pickup_latitude.max(), df_test.dropoff_latitude.max())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72e773257a0ecbfa2b8e4d47eea52c650bbd302e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# this function will also be used with the test set below\ndef select_within_boundingbox(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])\n            \n# load image of NYC map\nBB = (-74.5, -72.8, 40.5, 41.8)\nnyc_map = plt.imread('https://aiblog.nl/download/nyc_-74.5_-72.8_40.5_41.8.png')\n\n# load extra image to zoom in on NYC\nBB_zoom = (-74.3, -73.7, 40.5, 40.9)\nnyc_map_zoom = plt.imread('https://aiblog.nl/download/nyc_-74.3_-73.7_40.5_40.9.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6652992e7cb83cdaa22f288ff387326ad94c4e75"
      },
      "cell_type": "code",
      "source": "print('Old size: %d' % len(df_train))\ndf_train = df_train[select_within_boundingbox(df_train, BB)]\nprint('New size: %d' % len(df_train))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f8db4e178399b3e66fe0d6e3055adb8927f9c35",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# this function will be used more often to plot data on the NYC map\ndef plot_on_map(df, BB, nyc_map, s=10, alpha=0.2):\n    fig, axs = plt.subplots(1, 2, figsize=(16,10))\n    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[0].set_xlim((BB[0], BB[1]))\n    axs[0].set_ylim((BB[2], BB[3]))\n    axs[0].set_title('Pickup locations')\n    axs[0].imshow(nyc_map, zorder=0, extent=BB)\n\n    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[1].set_xlim((BB[0], BB[1]))\n    axs[1].set_ylim((BB[2], BB[3]))\n    axs[1].set_title('Dropoff locations')\n    axs[1].imshow(nyc_map, zorder=0, extent=BB)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96275cee1ea21ecb6453f4c664a649c747a38788"
      },
      "cell_type": "code",
      "source": "# plot training data on map\nplot_on_map(df_train, BB, nyc_map, s=1, alpha=0.3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98304d3e879df159c39508e381d1a93022052a6f"
      },
      "cell_type": "code",
      "source": "# plot training data on map zoomed in\nplot_on_map(df_train, BB_zoom, nyc_map_zoom, s=1, alpha=0.3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fbb36d6065efe28a97ef323e69f1ce5eb66fa6f8"
      },
      "cell_type": "code",
      "source": "# plot test data on map\nplot_on_map(df_test, BB, nyc_map, alpha=1.0, s=20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c73572469d74e4e8a81f8bed7f70f6f0b9924a61"
      },
      "cell_type": "markdown",
      "source": "From the training data scatter plot we see that some locations are in the water. Either these are considered as noise, or we drop them from the dataset. I decided to drop them (see next section).\n\nAn other interesting way to visualize the data I learned from this kernel: https://www.kaggle.com/drgilermo/dynamics-of-new-york-city-animation. By using very small dot sizes the actual streets of New York become visible."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "31d9df881c9aa64dd401a285140c4385cf688f32"
      },
      "cell_type": "code",
      "source": "def plot_hires(df, BB, figsize=(12, 12), ax=None, c=('r', 'b')):\n    if ax == None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    idx = select_within_boundingbox(df, BB)\n    ax.scatter(df[idx].pickup_longitude, df[idx].pickup_latitude, c=c[0], s=0.01, alpha=0.5)\n    ax.scatter(df[idx].dropoff_longitude, df[idx].dropoff_latitude, c=c[1], s=0.01, alpha=0.5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1060c21ebec1dda8567fcca3606a4ec41ad6ede"
      },
      "cell_type": "code",
      "source": "plot_hires(df_train, (-74.1, -73.7, 40.6, 40.9))\nplot_hires(df_train, (-74, -73.95, 40.7, 40.8))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "14b04d875ee8f66f01b98262625f5432505cd981"
      },
      "cell_type": "markdown",
      "source": "## Removing datapoints in water\nAs can be seen from the map + scatter plots above, some datapoints are located in the water. These are obviously noisy datapoints. To remove these datapoints, I create a boolean land/water map from the NYC map. For this I used Photoshop to threshold on the blue color of the water and to cleanup the map. The resulting map is show below."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "978e1d6ee3ff5fa2a67789f20f5c8888818b9740"
      },
      "cell_type": "code",
      "source": "# read nyc mask and turn into boolean map with\n# land = True, water = False\nnyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:,:,0] > 0.9\n\nplt.figure(figsize=(8,8))\nplt.imshow(nyc_map, zorder=0)\nplt.imshow(nyc_mask, zorder=1, alpha=0.7); # note: True is show in black, False in white.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "80042ec757a645d5220acd2123a34984388f98af"
      },
      "cell_type": "markdown",
      "source": "Next, I need to convert longitude/latitude coordinates to xy pixel coordinates. The function lonlat_to_xy implements this transformation. Note that the y coordinate needs to be reversed as the image y-axis is directed from top to bottom.\n\nOnce for all datapoints the xy pixel coordinates are calculate a boolean index is calculated using the NYC mask."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "aac888cc7d3da1d11fafaff8a9dd27fe8dbbc1a4"
      },
      "cell_type": "code",
      "source": "# translate longitude/latitude coordinate into image xy coordinate\ndef lonlat_to_xy(longitude, latitude, dx, dy, BB):\n    return (dx*(longitude - BB[0])/(BB[1]-BB[0])).astype('int'), \\\n           (dy - dy*(latitude - BB[2])/(BB[3]-BB[2])).astype('int')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "47e4bdabbe01a628e16d6917a8217b75ee98cb67"
      },
      "cell_type": "code",
      "source": "pickup_x, pickup_y = lonlat_to_xy(df_train.pickup_longitude, df_train.pickup_latitude, \n                                  nyc_mask.shape[1], nyc_mask.shape[0], BB)\ndropoff_x, dropoff_y = lonlat_to_xy(df_train.dropoff_longitude, df_train.dropoff_latitude, \n                                  nyc_mask.shape[1], nyc_mask.shape[0], BB)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53fbc7ca9c45629c76b674e73a7455a4da63a732"
      },
      "cell_type": "code",
      "source": "idx = (nyc_mask[pickup_y, pickup_x] & nyc_mask[dropoff_y, dropoff_x])\nprint(\"Number of trips in water: {}\".format(np.sum(~idx)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6387ae7bf338b1bb3bcc255dc2488992eb8ce347"
      },
      "cell_type": "markdown",
      "source": "Finally I create one function that can be reused to remove datapoints from water."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a98c25e83a98ebfa425d1af2c4c294d856936841"
      },
      "cell_type": "code",
      "source": "def remove_datapoints_from_water(df):\n    def lonlat_to_xy(longitude, latitude, dx, dy, BB):\n        return (dx*(longitude - BB[0])/(BB[1]-BB[0])).astype('int'), \\\n               (dy - dy*(latitude - BB[2])/(BB[3]-BB[2])).astype('int')\n\n    # define bounding box\n    BB = (-74.5, -72.8, 40.5, 41.8)\n    \n    # read nyc mask and turn into boolean map with\n    # land = True, water = False\n    nyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:,:,0] > 0.9\n    \n    # calculate for each lon,lat coordinate the xy coordinate in the mask map\n    pickup_x, pickup_y = lonlat_to_xy(df.pickup_longitude, df.pickup_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)\n    dropoff_x, dropoff_y = lonlat_to_xy(df.dropoff_longitude, df.dropoff_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)    \n    # calculate boolean index\n    idx = nyc_mask[pickup_y, pickup_x] & nyc_mask[dropoff_y, dropoff_x]\n    \n    # return only datapoints on land\n    return df[idx]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd1a159c9833b8fe751e07ae51eab416eba603bc"
      },
      "cell_type": "code",
      "source": "print('Old size: %d' % len(df_train))\ndf_train = remove_datapoints_from_water(df_train)\nprint('New size: %d' % len(df_train))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cecac6e057dd805aab73fe8bec5dc58b85d218a7"
      },
      "cell_type": "markdown",
      "source": "Now Let's see if all outliers in the water are gone ... :)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "70103699f9cae228a9daf0332e98fcf38abe5bf1"
      },
      "cell_type": "code",
      "source": "# plot training data\nplot_on_map(df_train, BB, nyc_map)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6feb5260e486844061b0a1ac9e271a16a57b00b9"
      },
      "cell_type": "markdown",
      "source": "\n### Datapoint density per sq mile\n\n\nA scatterplot of the pickup and dropoff locations gives a quick impression of the density. However, it is more accurate to count the number of datapoints per area to visualize the density. The code below counts pickup and dropoff datapoints per sq miles. This gives a better view on the 'hot spots'."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3686cd9adad8bf4bb4d684f9f39a82044ae94c5c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# For this plot and further analysis, we need a function to calculate the distance in miles between locations in lon,lat coordinates.\n# This function is based on https://stackoverflow.com/questions/27928/\n# calculate-distance-between-two-latitude-longitude-points-haversine-formula \n# return distance in miles\ndef distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin...\n\n# First calculate two arrays with datapoint density per sq mile\nn_lon, n_lat = 200, 200 # number of grid bins per longitude, latitude dimension\ndensity_pickup, density_dropoff = np.zeros((n_lat, n_lon)), np.zeros((n_lat, n_lon)) # prepare arrays\n\n# To calculate the number of datapoints in a grid area, the numpy.digitize() function is used. \n# This function needs an array with the (location) bins for counting the number of datapoints\n# per bin.\nbins_lon = np.zeros(n_lon+1) # bin\nbins_lat = np.zeros(n_lat+1) # bin\ndelta_lon = (BB[1]-BB[0]) / n_lon # bin longutide width\ndelta_lat = (BB[3]-BB[2]) / n_lat # bin latitude height\nbin_width_miles = distance(BB[2], BB[1], BB[2], BB[0]) / n_lon # bin width in miles\nbin_height_miles = distance(BB[3], BB[0], BB[2], BB[0]) / n_lat # bin height in miles\nfor i in range(n_lon+1):\n    bins_lon[i] = BB[0] + i * delta_lon\nfor j in range(n_lat+1):\n    bins_lat[j] = BB[2] + j * delta_lat\n    \n# Digitize per longitude, latitude dimension\ninds_pickup_lon = np.digitize(df_train.pickup_longitude, bins_lon)\ninds_pickup_lat = np.digitize(df_train.pickup_latitude, bins_lat)\ninds_dropoff_lon = np.digitize(df_train.dropoff_longitude, bins_lon)\ninds_dropoff_lat = np.digitize(df_train.dropoff_latitude, bins_lat)\n\n# Count per grid bin\n# note: as the density_pickup will be displayed as image, the first index is the y-direction, \n#       the second index is the x-direction. Also, the y-direction needs to be reversed for\n#       properly displaying (therefore the (n_lat-j) term)\ndxdy = bin_width_miles * bin_height_miles\nfor i in range(n_lon):\n    for j in range(n_lat):\n        density_pickup[j, i] = np.sum((inds_pickup_lon==i+1) & (inds_pickup_lat==(n_lat-j))) / dxdy\n        density_dropoff[j, i] = np.sum((inds_dropoff_lon==i+1) & (inds_dropoff_lat==(n_lat-j))) / dxdy",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "25fc60da96b02dc35cb4aebfdb56fb9252aa9600"
      },
      "cell_type": "code",
      "source": "# Plot the density arrays\nfig, axs = plt.subplots(2, 1, figsize=(18, 24))\naxs[0].imshow(nyc_map, zorder=0, extent=BB);\nim = axs[0].imshow(np.log1p(density_pickup), zorder=1, extent=BB, alpha=0.6, cmap='plasma')\naxs[0].set_title('Pickup density [datapoints per sq mile]')\ncbar = fig.colorbar(im, ax=axs[0])\ncbar.set_label('log(1 + #datapoints per sq mile)', rotation=270)\n\naxs[1].imshow(nyc_map, zorder=0, extent=BB);\nim = axs[1].imshow(np.log1p(density_dropoff), zorder=1, extent=BB, alpha=0.6, cmap='plasma')\naxs[1].set_title('Dropoff density [datapoints per sq mile]')\ncbar = fig.colorbar(im, ax=axs[1])\ncbar.set_label('log(1 + #datapoints per sq mile)', rotation=270)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1c446fe9bc88d45f934bfb5e33dbdb215a939ae8"
      },
      "cell_type": "markdown",
      "source": "These plots clearly show that the datapoints concentrate around Manhatten and the three airports (JFK, EWS, LGR). There is also a hotspot near Seymour (upper right corner). As I'm not from the US, does somebody has an idea what's so special about this location?\n"
    },
    {
      "metadata": {
        "_uuid": "a1ce51035f5a7fe46021f7daae87f72d1b2a7b38"
      },
      "cell_type": "markdown",
      "source": "## Pickup traffic density\nThe density plots of above triggered me to see if I can visualize traffic density by the hour (and year). By counting the number of pickups in an area we should get some impression of the traffic density. The more traffic, the longer it could take to make a drive."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0b8dec6332dbc4bd49837b7ec71d7c47eb5ddd7a"
      },
      "cell_type": "code",
      "source": "# add time information\ndf_train['year'] = df_train.pickup_datetime.apply(lambda t: t.year)\ndf_train['weekday'] = df_train.pickup_datetime.apply(lambda t: t.weekday())\ndf_train['hour'] = df_train.pickup_datetime.apply(lambda t: t.hour)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f37ce7f769b2005470efe5343c0f432b7f70e9b9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# some constants needed to calculate pickup traffic density\nn_hours = 24\nn_weekdays = 7\nn_years = 7\nn_bins_lon = 30\nn_bins_lat = 30\n\n# focus on traffic in Manhattan\nBB_traffic = (-74.025, -73.925, 40.7, 40.8)\n\n# define function to calculate pickup traffic density\ndef calculate_trafic_density(df):\n    traffic = np.zeros((n_years, n_weekdays, n_hours, n_bins_lat, n_bins_lon))\n    \n    # To calculate the number of datapoints in a grid area, the numpy.digitize() function is used. \n    # This function needs an array with the (location) bins for counting the number of datapoints\n    # per bin.\n    bins_lon = np.zeros(n_bins_lon+1) # bin\n    bins_lat = np.zeros(n_bins_lat+1) # bin\n    \n    delta_lon = (BB_traffic[1]-BB_traffic[0]) / n_bins_lon # bin longutide width\n    delta_lat = (BB_traffic[3]-BB_traffic[2]) / n_bins_lat # bin latitude height\n    \n    for i in range(n_bins_lon+1):\n        bins_lon[i] = BB_traffic[0] + i * delta_lon\n    for j in range(n_bins_lat+1):\n        bins_lat[j] = BB_traffic[2] + j * delta_lat\n    \n    # Count per grid bin\n    # note: as the density_pickup will be displayed as image, the first index is the y-direction, \n    #       the second index is the x-direction. Also, the y-direction needs to be reversed for\n    #       properly displaying (therefore the (n_lat-j) term)\n    for y in range(n_years):\n        for d in range(n_weekdays):\n            for h in range(n_hours):\n                idx = (df.year==(2009+y)) & (df.weekday==d) & (df.hour==h)\n\n                # Digitize per longitude, latitude dimension\n                inds_pickup_lon = np.digitize(df[idx].pickup_longitude, bins_lon)\n                inds_pickup_lat = np.digitize(df[idx].pickup_latitude, bins_lat)\n\n                for i in range(n_bins_lon):\n                    for j in range(n_bins_lat):\n                        traffic[y, d, h, j, i] = traffic[y, d, h, j, i] + \\\n                                                 np.sum((inds_pickup_lon==i+1) & (inds_pickup_lat==j+1))\n    \n    return traffic \n\n# define function to plot pickup traffic density\ndef plot_traffic(traffic, y, d):\n    days = {'monday' : 0, 'tuesday' : 1, 'wednesday' : 2, 'thursday' : 3, 'friday' : 4, 'saturday' : 5, 'sunday' : 6}\n    fig, axs = plt.subplots(3,8,figsize=(18,7))\n    axs = axs.ravel()\n    for h in range(24):\n        axs[h].imshow(traffic[y-2009,days[d],h,::-1,:], zorder=1, cmap='coolwarm', clim=(0, traffic.max()))\n        axs[h].get_xaxis().set_visible(False)\n        axs[h].get_yaxis().set_visible(False)\n        axs[h].set_title('h={}'.format(h))\n    fig.suptitle(\"Pickup traffic density, year={}, day={} (max_pickups={})\".format(y, d, traffic.max()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f41225b8d3df7a70a69a5a43aae11d0cc0fd9801"
      },
      "cell_type": "markdown",
      "source": "Now, let's calculate the density and visualize the plots. \n\nNOTE: the quality of the plots depends on the number of datapoints used. This notebook uses by default 500k points, which is not sufficient for good traffic density plots. Increase the number of points and you get better plots."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "43d8c7ae94cb6d8ba3f7754a825c45834d2a46dc",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "traffic = calculate_trafic_density(df_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f1526625b3d7b02cf80acf0eb9afc319c25f4bdc"
      },
      "cell_type": "code",
      "source": "plot_traffic(traffic, 2009, 'monday')\nplot_traffic(traffic, 2009, 'friday')\nplot_traffic(traffic, 2009, 'sunday')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2764d8b87589b25ff46fe661be5dd3a98c69fd87"
      },
      "cell_type": "markdown",
      "source": "Already from these plots we can see the different traffic density patterns by the hour, but also by location. E.g. at sunday h=0-3 hour (saturday night to sunday) there is more traffic than on weekdays. I presume this is from people going out and enjoying the weekend.  Let's also visualize an other year."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e7322ab8be2e39304a9b9da2a0b9cce9248d4a9"
      },
      "cell_type": "code",
      "source": "plot_traffic(traffic, 2014, 'monday')\nplot_traffic(traffic, 2014, 'friday')\nplot_traffic(traffic, 2014, 'sunday')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1eceb1056faa82edd69e3a5abe5e440fe3017a49"
      },
      "cell_type": "markdown",
      "source": "## Distance and time visualisations\n\nBefore building a model I want to test some basic 'intuition':\n\n- The longer the distance between pickup and dropoff location, the higher the fare.\n- Some trips, like to/from an airport, are fixed fee. \n- Fare at night is different from day time.\n\nSo, let's check."
    },
    {
      "metadata": {
        "_uuid": "0e8450868fa440d5428dfb020a6b39b06417b8d6"
      },
      "cell_type": "markdown",
      "source": "### The longer the distance between pickup and dropoff location, the higher the fare\n\nTo visualize the distance - fare relation we need to calculate the distance of a trip first. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f91f77105f0c87ba5dd09305f544eaf72657490b"
      },
      "cell_type": "code",
      "source": "# add new column to dataframe with distance in miles\ndf_train['distance_miles'] = distance(df_train.pickup_latitude, df_train.pickup_longitude, \\\n                                      df_train.dropoff_latitude, df_train.dropoff_longitude)\n\ndf_train.distance_miles.hist(bins=50, figsize=(12,4))\nplt.xlabel('distance miles')\nplt.title('Histogram ride distances in miles')\ndf_train.distance_miles.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d30efafceafdb6e5068679eb3b05b27311482237"
      },
      "cell_type": "markdown",
      "source": "It seems that most rides are just short rides, with a small peak at ~13 miles. This peak could be due to airport drives.\n\nLet's also see the influence of `passenger_count`."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7bc1745aa9fe669f24859088ee7bbcf106fae362"
      },
      "cell_type": "code",
      "source": "df_train.groupby('passenger_count')['distance_miles', 'fare_amount'].mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fcc8aeddfa31d91dceda51c0fd201d40a4b86019"
      },
      "cell_type": "markdown",
      "source": "A `passenger_count` of zero seems odd. Perhaps a taxi transporting some goods or an administration error? The latter seems not the case as the `fare_amount` is also significantly lower.\n\nInstead of looking to the `fare_amount` using the 'fare per mile' also provides some insights."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2f06a1a44abebc4c23f7ba4017a5057aa52ba204"
      },
      "cell_type": "code",
      "source": "print(\"Average $USD/Mile : {:0.2f}\".format(df_train.fare_amount.sum()/df_train.distance_miles.sum()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0ffc498bddf6609dd6ef4ecb4954eaef0c27e0e"
      },
      "cell_type": "code",
      "source": "# scatter plot distance - fare\nfig, axs = plt.subplots(1, 2, figsize=(16,6))\naxs[0].scatter(df_train.distance_miles, df_train.fare_amount, alpha=0.2)\naxs[0].set_xlabel('distance mile')\naxs[0].set_ylabel('fare $USD')\naxs[0].set_title('All data')\n\n# zoom in on part of data\nidx = (df_train.distance_miles < 15) & (df_train.fare_amount < 100)\naxs[1].scatter(df_train[idx].distance_miles, df_train[idx].fare_amount, alpha=0.2)\naxs[1].set_xlabel('distance mile')\naxs[1].set_ylabel('fare $USD')\naxs[1].set_title('Zoom in on distance < 15 mile, fare < $100');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d0f78fa6f6f96ec4d693a0a09307b5a7731bd054"
      },
      "cell_type": "markdown",
      "source": "From this plot we notice:\n\n- There are trips with zero distance but with a non-zero fare. Could this be trips from and to the same location? Predicting these fares will be difficult as there is likely not sufficient information in the dataset.\n- There are some trips with >50 miles travel distance but low fare. Perhaps these are discounted trips? Or the previously mentioned hotspot near Seymour (see density plots above)?\n- The horizontal lines in the right plot might indicate again the fixed fare trips to/from JFK airport.\n- Overall there seems to be a (linear) relation between distance and fare with an average rate of +/- 100/20 = 5 \\$USD/mile.\n\nConsidering the last point, when I google for NYC taxi fare prices I find:\n\n- \\$4.00 – \\$10.00 for 3km trip (https://www.priceoftravel.com/555/world-taxi-prices-what-a-3-kilometer-ride-costs-in-72-big-cities/)\n- Start range: \\$2.50 - \\$3.30, 1km range: \\$1.55 - \\$2.98 (https://www.numbeo.com/taxi-fare/in/New-York)\n- A detailed description of the taxi prices: http://home.nyc.gov/html/tlc/html/passenger/taxicab_rate.shtml\n    - Initial charge for most rides (excluding from JFK and other airports) is \\$2.50 upon entry. After that there \\$0.5 every unit where the unit is defined as 1/5th of a mile or when the Taxicab is travelling 12 Miles an hour or more...since we can't decipher the velocity of the car, I would take 1/5th of a mile as the unit and convert the distance into this unit.\n    - \\$0.5 of additional surcharge between 8PM - 6AM.\n    - Peak hour weekday surcharge of \\$1 Monday-Friday between 4PM-8PM.\n    - There is a \\$0.5 MTA State Surcharge for all trips that end in New York City or Nassau, Suffolk, Westchester, Rockland, Dutchess, Orange or Putnam Counties.\n    - There is a \\$0.3 Improvement surcharge\n\nNote: the calculated distance in the dataset is from point to point. In reality, the distance measured by road is larger."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3aab0478c047c0eb1a6ac80097a931a4cfd9b9b4"
      },
      "cell_type": "code",
      "source": "# remove datapoints with distance <0.05 miles\nidx = (df_train.distance_miles >= 0.05)\nprint('Old size: %d' % len(df_train))\ndf_train = df_train[idx]\nprint('New size: %d' % len(df_train))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "156533df0f5715bb58992530a43df212c9aa4735"
      },
      "cell_type": "markdown",
      "source": "## Some trips, like to/from an airport, are fixed fee\n\nAnother way to explore this data is to check trips to/from well known places. E.g. a trip to JFK airport. Depending on the distance, a trip to an airport is often a fixed price. Let's see."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf424d104e596caf9b1e2f71b32b5d08bbb9efac"
      },
      "cell_type": "code",
      "source": "# JFK airport coordinates, see https://www.travelmath.com/airport/JFK\njfk = (-73.7822222222, 40.6441666667)\nnyc = (-74.0063889, 40.7141667)\n\ndef plot_location_fare(loc, name, range=1.5):\n    # select all datapoints with dropoff location within range of airport\n    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n    idx = (distance(df_train.pickup_latitude, df_train.pickup_longitude, loc[1], loc[0]) < range)\n    df_train[idx].fare_amount.hist(bins=100, ax=axs[0])\n    axs[0].set_xlabel('fare $USD')\n    axs[0].set_title('Histogram pickup location within {} miles of {}'.format(range, name))\n\n    idx = (distance(df_train.dropoff_latitude, df_train.dropoff_longitude, loc[1], loc[0]) < range)\n    df_train[idx].fare_amount.hist(bins=100, ax=axs[1])\n    axs[1].set_xlabel('fare $USD')\n    axs[1].set_title('Histogram dropoff location within {} miles of {}'.format(range, name));\n    \nplot_location_fare(jfk, 'JFK Airport')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "98d5f53a7a1e3b8ce0cb1df48eb4c597e2b608ff"
      },
      "cell_type": "markdown",
      "source": "It seems that there are some fixed prices to/from the airport. Also, somebody might have paid way too much ($250??)!\n\nLet's do the same for the other two airports."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "149a4abd37914dca5ef8bb25bf7d4bc8402e9a17"
      },
      "cell_type": "code",
      "source": "ewr = (-74.175, 40.69) # Newark Liberty International Airport, see https://www.travelmath.com/airport/EWR\nlgr = (-73.87, 40.77) # LaGuardia Airport, see https://www.travelmath.com/airport/LGA\nplot_location_fare(ewr, 'Newark Airport')\nplot_location_fare(lgr, 'LaGuardia Airport')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3cec49ceda7377b858745211d437cca97da32441"
      },
      "cell_type": "markdown",
      "source": "## Fare at night is different from day time\n\nTo visualize the relation between time and fare/km three more columns are added to the data: the year, the hour of the day and the fare $USD per KM."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "097215a28be8d9827565e011d364d33f2997dc65"
      },
      "cell_type": "code",
      "source": "df_train['fare_per_mile'] = df_train.fare_amount / df_train.distance_miles\ndf_train.fare_per_mile.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "32e4bec8d1bfe268537ab97d2bd79a97b5a48335"
      },
      "cell_type": "markdown",
      "source": "The maximum fare \\$USD/mile seem to be very high. This could be due to wrong distance or fare data. On the other hand, let's analyse this somewhat further. In general taxi fare is calculate by\n\n$$\ny_{fare} = \\theta_0 + \\theta_1 \\cdot x_{distance} + \\theta_2 \\cdot x_{duration}\n$$\n\nwith $\\theta_0$ the starting tariff, $x_{distance}$ the distance travelled and $x_{duration}$ the duration of the trip. If we rewrite this we get an expression for the fare per distance:\n\n$$\n\\frac{y_{fare}}{x_{distance}} = \\frac{\\theta_0}{x_{distance}} + \\theta_1 + \\theta_2 \\cdot \\frac{x_{duration}}{ x_{distance}}\n$$\n\nLet's further assume for the shorter trips that $x_{distance} = c \\cdot x_{duration}$ with $c$ the average speed, then we get\n\n$$\n\\frac{y_{fare}}{x_{distance}} = \\frac{\\theta_0}{x_{distance}} + \\theta_1 + \\frac{\\theta_2}{c} \\cdot \\frac{x_{duration}}{x_{duration}} = \\frac{\\theta_0}{x_{distance}} + \\theta_1'\n$$\n\nwith $\\theta_1' = \\theta_1 + \\theta_2 / c$.\n\nConclusion: the fare per distance is proportional to $1/\\text{distance_mile}$. Let's plot the data and a graph.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34a0957966db7c401db0e3db48dccc1ff7787b1c"
      },
      "cell_type": "code",
      "source": "idx = (df_train.distance_miles < 3) & (df_train.fare_amount < 100)\nplt.scatter(df_train[idx].distance_miles, df_train[idx].fare_per_mile)\nplt.xlabel('distance mile')\nplt.ylabel('fare per distance mile')\n\n# theta here is estimated by hand\ntheta = (16, 4.0)\nx = np.linspace(0.1, 3, 50)\nplt.plot(x, theta[0]/x + theta[1], '--', c='r', lw=2);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "857f243816b43d06bc9cc6731ae36d866bfc3c31"
      },
      "cell_type": "markdown",
      "source": "Note that the fare per distance has more spread for smaller distances (<0.5 mile) than larger distances. This could be explained as follows:  we measure the distance from point to point and not by road. For smaller distances the difference between these two measurement methods is expected to be larger. This is one aspect I would guess a more advanced model (deep learning NN) would improve upon compared to a linear model.\n\n[30/07/2018] An other reason why the spread for smaller distances is larger could be due to slow traffic at rush hours. Short drives at rush hours vary more in duration."
    },
    {
      "metadata": {
        "_uuid": "15ee1b6c7f74c3545bb1538bf90de46de8af05ca"
      },
      "cell_type": "markdown",
      "source": "Let's continue with the time vs fare per distance analysis. Next we use a pandas pivot table to calculate a summary and to plot them."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad29c60c7f00080419747913002ba9be847d6b87"
      },
      "cell_type": "code",
      "source": "# display pivot table\ndf_train.pivot_table('fare_per_mile', index='hour', columns='year').plot(figsize=(14,6))\nplt.ylabel('Fare $USD / mile');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8dab0dd25d4d17b6eb4da9e8e91ddc92b24e3124"
      },
      "cell_type": "markdown",
      "source": "It can be clearly seen that the fare $USD/mile varies over the years and over the hours. \n\nTo investigate this further I used Google map to calculate the expected duration of two trips:\n\n- Trip 1 : from Museum of the City of New York to Beacon Theatre, 4.5km, not leaving Manhatten\n- Trip 2 : from Times Squared to Maria Hermandez Park, 12km, leaving Times Squared via Queens Midtown Tunnel (Toll road)\n\nBelow are the data and graphs. I do see the same type of graph. So, amount of traffic determines the duration of the trip and thus the fare. While the amount of traffic depends on the hour of the day."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3202cce21b22fdbe33fb99e6b50b5c37861be7e"
      },
      "cell_type": "code",
      "source": "hours = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \\\n         13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n\n# minimum & maximum duration in minutes\ntrip1_min = [10, 10, 10, 10, 10, 10, 10, 12, 14, 14, 14, 14, \\\n             14, 14, 14, 14, 14, 12, 12, 12, 12, 12, 10, 10]\ntrip1_max = [20, 18, 16, 16, 16, 18, 22, 26, 40, 35, 35, 35, \\\n             35, 35, 35, 40, 35, 30, 28, 28, 26, 26, 24, 24]\n\ntrip2_min = [18, 18, 18, 18, 18, 18, 20, 24, 28, 30, 30, 30, \\\n             28, 28, 26, 28, 30, 28, 26, 22, 22, 22, 20, 20]\ntrip2_max = [35, 35, 30, 28, 28, 30, 40, 55, 75, 75, 70, 70, \\\n             60, 60, 60, 60, 60, 65, 55, 45, 45, 50, 45, 40]\n\nplt.figure(figsize=(12, 5))\nplt.plot(hours, trip1_min, '--', c='b', label=\"trip1 (2.7 mile) - minimum duration\")\nplt.plot(hours, trip1_max, '-', c='b', label=\"trip1 (2.7 mile) - maximum duration\")\nplt.plot(hours, trip2_min, '--', c='r', label=\"trip2 (7.2 mile) - minimum duration\")\nplt.plot(hours, trip2_max, '-', c='r', label=\"trip2 (7.2 mile) - maximum duration\")\nplt.xlabel('hour of the day')\nplt.ylabel('driving time (min)')\nplt.title('Estimated driving time for two trips using Google Map traffic info')\nplt.legend();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5403dfce00954e8b300f7a0b74433e6f617011e6"
      },
      "cell_type": "markdown",
      "source": "A more in-depth analysis of the fare / time dependency is illustrated below. Here, I calculate per year and per hour the fare and do a linear regression. When investigating the plots, you clearly see the price increase over the years."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca4675da41ce7e317575ef816d157a919d8acc11"
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LinearRegression\n\n# plot all years\nfor year in df_train.year.unique():\n    # create figure\n    fig, axs = plt.subplots(4, 6, figsize=(18, 10))\n    axs = axs.ravel()\n    \n    # plot for all hours\n    for h in range(24):\n        idx = (df_train.distance_miles < 15) & (df_train.fare_amount < 100) & (df_train.hour == h) & \\\n              (df_train.year == year)\n        axs[h].scatter(df_train[idx].distance_miles, df_train[idx].fare_amount, alpha=0.2, s=1)\n        axs[h].set_xlabel('distance miles')\n        axs[h].set_ylabel('fare $USD')\n        axs[h].set_xlim((0, 15))\n        axs[h].set_ylim((0, 70))\n\n        model = LinearRegression(fit_intercept=False)\n        x, y = df_train[idx].distance_miles.values.reshape(-1,1), df_train[idx].fare_amount.values.reshape(-1,1)\n        X = np.concatenate((np.ones(x.shape), x), axis=1)\n        model.fit(X, y)\n        xx = np.linspace(0.1, 25, 100)\n        axs[h].plot(xx, model.coef_[0][0] + xx * model.coef_[0][1], '--', c='r', lw=2)\n        axs[h].set_title('hour = {}, theta=({:0.2f},{:0.2f})'.format(h, model.coef_[0][0], model.coef_[0][1]))\n\n    plt.suptitle(\"Year = {}\".format(year))\n    plt.tight_layout(rect=[0, 0, 1, 0.95]);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5d56e3a391a0fd5308fd251c09ba63b00ad22a0b"
      },
      "cell_type": "markdown",
      "source": "## Fare varies with pickup location\n\nTo visualize whether the fare per km varies with the location the distance to the center of New York is calculated. "
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "cfffe04e6b52d79a17acf7dadf77487920523b97"
      },
      "cell_type": "code",
      "source": "# add new column to dataframe with distance in mile\ndf_train['distance_to_center'] = distance(nyc[1], nyc[0], df_train.pickup_latitude, df_train.pickup_longitude)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5af378bafe7c04bc2047602c1613b1c8bd49cf5b"
      },
      "cell_type": "markdown",
      "source": "Plotting the distance to NYC center vs distance of the trip vs the fare amount gives some insight in this complex relation. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5563e54b47810662ebb9bc593ce585b6c95f645"
      },
      "cell_type": "code",
      "source": "fig, axs = plt.subplots(1, 2, figsize=(16,6))\nim = axs[0].scatter(df_train.distance_to_center, df_train.distance_miles, c=np.clip(df_train.fare_amount, 0, 100), \n                     cmap='viridis', alpha=1.0, s=1)\naxs[0].set_xlabel('pickup distance from NYC center')\naxs[0].set_ylabel('distance miles')\naxs[0].set_title('All data')\ncbar = fig.colorbar(im, ax=axs[0])\ncbar.ax.set_ylabel('fare_amount', rotation=270)\n\nidx = (df_train.distance_to_center < 15) & (df_train.distance_miles < 35)\nim = axs[1].scatter(df_train[idx].distance_to_center, df_train[idx].distance_miles, \n                     c=np.clip(df_train[idx].fare_amount, 0, 100), cmap='viridis', alpha=1.0, s=1)\naxs[1].set_xlabel('pickup distance from NYC center')\naxs[1].set_ylabel('distance miles')\naxs[1].set_title('Zoom in')\ncbar = fig.colorbar(im, ax=axs[1])\ncbar.ax.set_ylabel('fare_amount', rotation=270);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3d8cb47d4b7229d1af382db02cae3cc95f34724a"
      },
      "cell_type": "markdown",
      "source": "There is a lot of 'green' dots, which is about \\$50 to \\$60 fare amount near 13 miles distance of NYC center of distrance of trip. This could be due to trips from/to JFK airport. Let's remove them to see what we're left with."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "88b81c28ff48e7d4ee8f5868ab0cdfa03b9d4e65"
      },
      "cell_type": "code",
      "source": "df_train['pickup_distance_to_jfk'] = distance(jfk[1], jfk[0], df_train.pickup_latitude, df_train.pickup_longitude)\ndf_train['dropoff_distance_to_jfk'] = distance(jfk[1], jfk[0], df_train.dropoff_latitude, df_train.dropoff_longitude)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a92c9b6e5d50ae2ae75931a8d799d158292a993a"
      },
      "cell_type": "code",
      "source": "# remove all to/from JFK trips\nidx = ~((df_train.pickup_distance_to_jfk < 1) | (df_train.dropoff_distance_to_jfk < 1))\n\nfig, axs = plt.subplots(1, 2, figsize=(16,6))\nim = axs[0].scatter(df_train[idx].distance_to_center, df_train[idx].distance_miles, \n                    c=np.clip(df_train[idx].fare_amount, 0, 100), \n                     cmap='viridis', alpha=1.0, s=1)\naxs[0].set_xlabel('pickup distance from NYC center')\naxs[0].set_ylabel('distance miles')\naxs[0].set_title('All data')\ncbar = fig.colorbar(im, ax=axs[0])\ncbar.ax.set_ylabel('fare_amount', rotation=270)\n\nidx1 = idx & (df_train.distance_to_center < 15) & (df_train.distance_miles < 35)\nim = axs[1].scatter(df_train[idx1].distance_to_center, df_train[idx1].distance_miles, \n                     c=np.clip(df_train[idx1].fare_amount, 0, 100), cmap='viridis', alpha=1.0, s=1)\naxs[1].set_xlabel('pickup distance from NYC center')\naxs[1].set_ylabel('distance miles')\naxs[1].set_title('Zoom in')\ncbar = fig.colorbar(im, ax=axs[1])\ncbar.ax.set_ylabel('fare_amount', rotation=270);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "57d541394615e8df82a4b3cb36106fc0d4234439"
      },
      "cell_type": "markdown",
      "source": "Now there are some 'yellow' dots (fare amount > \\$80) left. To understand these datapoints we plot them on the map."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "99220b184a75ba4de37bf69dfcbb43ad7a7c96e4"
      },
      "cell_type": "code",
      "source": "idx = (df_train.fare_amount>80) & (df_train.distance_miles<35) \nplot_on_map(df_train[idx], BB, nyc_map)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d9ad25c595f70f160356b97bbbb2d0109b685626"
      },
      "cell_type": "markdown",
      "source": "There seem to be a concentration of datapoints near dropoff (-74.2, 40.65). After looking these coordinates up on Google map I learned NYC has a second airport: Newark Liberty International Airport. The fare from/to the airport from NYC center is around $80-$100 USD. \n\nLet's remove also these datapoints to see if my findings are right. As there is also a third airport, LaGuardia Airport, I remove them too."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "c83c0b973ce3a1cb4570699140a506a35a260f79"
      },
      "cell_type": "code",
      "source": "df_train['pickup_distance_to_ewr'] = distance(ewr[1], ewr[0], df_train.pickup_latitude, df_train.pickup_longitude)\ndf_train['dropoff_distance_to_ewr'] = distance(ewr[1], ewr[0], df_train.dropoff_latitude, df_train.dropoff_longitude)\ndf_train['pickup_distance_to_lgr'] = distance(lgr[1], lgr[0], df_train.pickup_latitude, df_train.pickup_longitude)\ndf_train['dropoff_distance_to_lgr'] = distance(lgr[1], lgr[0], df_train.dropoff_latitude, df_train.dropoff_longitude)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c36ef6ea24475910ad6845a29823f43e4dc564d3"
      },
      "cell_type": "code",
      "source": "# remove all to/from airport trips\nidx = ~((df_train.pickup_distance_to_jfk < 1) | (df_train.dropoff_distance_to_jfk < 1) |\n        (df_train.pickup_distance_to_ewr < 1) | (df_train.dropoff_distance_to_ewr < 1) |\n        (df_train.pickup_distance_to_lgr < 1) | (df_train.dropoff_distance_to_lgr < 1))\n\nfig, axs = plt.subplots(1, 2, figsize=(16,6))\nim = axs[0].scatter(df_train[idx].distance_to_center, df_train[idx].distance_miles, \n                    c=np.clip(df_train[idx].fare_amount, 0, 100), \n                     cmap='viridis', alpha=1.0, s=1)\naxs[0].set_xlabel('pickup distance from NYC center')\naxs[0].set_ylabel('distance miles')\naxs[0].set_title('All data')\ncbar = fig.colorbar(im, ax=axs[0])\ncbar.ax.set_ylabel('fare_amount', rotation=270)\n\nidx1 = idx & (df_train.distance_to_center < 15) & (df_train.distance_miles < 35)\nim = axs[1].scatter(df_train[idx1].distance_to_center, df_train[idx1].distance_miles, \n                     c=np.clip(df_train[idx1].fare_amount, 0, 100), cmap='viridis', alpha=1.0, s=1)\naxs[1].set_xlabel('pickup distance from NYC center')\naxs[1].set_ylabel('distance miles')\naxs[1].set_title('Zoom in')\ncbar = fig.colorbar(im, ax=axs[1])\ncbar.ax.set_ylabel('fare_amount', rotation=270);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4370ff514d0a19c905416a81d8789fbc756fd371"
      },
      "cell_type": "markdown",
      "source": "Removing the to/from airport trips seems to give a more 'linear' view of the data. Fare amount depends on distance travelled and not so much on starting position."
    },
    {
      "metadata": {
        "_uuid": "48058ed24175fdf84109b846eb78c27a88a20f1a"
      },
      "cell_type": "markdown",
      "source": "## Relevance of direction for fare amount\nUpto now I mainly considered the total distance of a trip as a main feature for predicting the fare amount. However, what about the direction of a trip? To visualise this, I start with a simple plot of the delta longitude and latitude and the fare amount."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6adb12393ba1a157578fec130e5c3aa8a5512019"
      },
      "cell_type": "code",
      "source": "df_train['delta_lon'] = df_train.pickup_longitude - df_train.dropoff_longitude\ndf_train['delta_lat'] = df_train.pickup_latitude - df_train.dropoff_latitude\n\n# Select trips in Manhattan\nBB_manhattan = (-74.025, -73.925, 40.7, 40.8)\nidx_manhattan = select_within_boundingbox(df_train, BB_manhattan)\n\nplt.figure(figsize=(14,8))\nplt.scatter(df_train[idx_manhattan].delta_lon, df_train[idx_manhattan].delta_lat, s=0.5, alpha=1.0, \n            c=np.log1p(df_train[idx_manhattan].fare_amount), cmap='magma')\nplt.colorbar()\nplt.xlabel('pickup_longitude - dropoff_longitude')\nplt.ylabel('pickup_latitude - dropoff_latidue')\nplt.title('log1p(fare_amount)');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "796c9e444828db8cd1d6493e81b4d21d5aac93d9"
      },
      "cell_type": "markdown",
      "source": "As can be  seen from this plot, the direction of the trip seems to matter!! Therefore, let's calculate the precise direction (in degrees) and plot the direction vs fare amount."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23b5ed58ee70fd23bf8fe4ef8b04cc3f2f7a6636"
      },
      "cell_type": "code",
      "source": "# direction of a trip, from 180 to -180 degrees. Horizontal axes = 0 degrees.\ndef calculate_direction(d_lon, d_lat):\n    result = np.zeros(len(d_lon))\n    l = np.sqrt(d_lon**2 + d_lat**2)\n    result[d_lon>0] = (180/np.pi)*np.arcsin(d_lat[d_lon>0]/l[d_lon>0])\n    idx = (d_lon<0) & (d_lat>0)\n    result[idx] = 180 - (180/np.pi)*np.arcsin(d_lat[idx]/l[idx])\n    idx = (d_lon<0) & (d_lat<0)\n    result[idx] = -180 - (180/np.pi)*np.arcsin(d_lat[idx]/l[idx])\n    return result\n\ndf_train['direction'] = calculate_direction(df_train.delta_lon, df_train.delta_lat)\n\n# plot histogram of directions\nplt.figure(figsize=(10,6))\ndf_train[idx_manhattan].direction.hist(bins=180)\nplt.xlabel('direction (degrees)')\nplt.title('Histogram direction (Manhattan)')\n\n# plot direction vs average fare amount\nfig, ax = plt.subplots(1, 1, figsize=(14,6))\ndirec = pd.cut(df_train[idx_manhattan]['direction'], np.linspace(-180, 180, 37))\ndf_train[idx_manhattan].pivot_table('fare_amount', index=[direc], columns='year', aggfunc='mean').plot(ax=ax)\nplt.xlabel('direction (degrees)')\nplt.xticks(range(36), np.arange(-170, 190, 10))\nplt.ylabel('average fare amount $USD');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e39d068020166ae3b678a1b4c4d7e634cb37452d"
      },
      "cell_type": "markdown",
      "source": "Now, clear the average fare amount in Manhattan depends on the direction. This is not too surprisingly, as the streets in Manhattan have a angle of about 60 degrees with the horizon. In the 60 degrees direction Manhatten is longer than in the direction perpendicular to this (-30 degrees). To investigate the influence of the direction to the fare amount further we should consider trips with the some length. See below."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "623d01d93aa8cd682fbc43b0863c2696bb48c1df"
      },
      "cell_type": "code",
      "source": "# select trips in Manhattan with +/- 2 miles distance drive\nidx2 = idx_manhattan & (df_train.distance_miles>1.5) & (df_train.distance_miles<1.7)\n\n# plot direction vs average fare amount\nfig, ax = plt.subplots(1, 1, figsize=(14,6))\ndirec = pd.cut(df_train[idx2]['direction'], np.linspace(-180, 180, 37))\ndf_train[idx2].pivot_table('fare_amount', index=[direc], columns='year', aggfunc='mean').plot(ax=ax)\nplt.xlabel('direction (degrees)')\nplt.xticks(range(36), np.arange(-170, 190, 10))\nplt.ylabel('average fare amount $USD');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e65e1e872062392a087d06e5e9134bfdf9e6005d"
      },
      "cell_type": "markdown",
      "source": "So, even for trips with the same length we see the influence of the direction on the fare amount. The notebook of Oliver (https://www.kaggle.com/ojones3/feature-engineering-corrected-manhattan-distance) explains the difference in calculating the distance of a trip using Euclidean vs Manhattan distance measure. The distance calculated in this notebook is the direct point-to-point distance. This is not the true distance of the trip. Using the Manhattan distance gives a better approximation *if* the streets are aligned to the vertical and horizontal axis. That is, if we turn the streets 60 degrees. \n\nThis is the reason that the average fare for direction=60 or -120 is the lowest, as the distance at these angles is the true distance (driving down a street without turns). If the direction is different from 60 or -120 degrees, this means that the distance of the trip in reality is larger, so a higher fare amount."
    },
    {
      "metadata": {
        "_uuid": "93bc35cbaa1b0e7627ceb4f6cd2795abc6215c9c"
      },
      "cell_type": "markdown",
      "source": "# Generate Kaggle baseline model and submission\n\nAlso explore the test set, e.g. to see if the data has the same properties."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38196b8bd9ca84b55fe7c6c3536b95c926b63dae",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# add new column to dataframe with distance in km\ndf_test['distance_miles'] = distance(df_test.pickup_latitude, df_test.pickup_longitude, \\\n                                     df_test.dropoff_latitude, df_test.dropoff_longitude)\ndf_test['distance_to_center'] = distance(nyc[1], nyc[0], \\\n                                          df_test.dropoff_latitude, df_test.dropoff_longitude)\ndf_test['hour'] = df_test.pickup_datetime.apply(lambda t: pd.to_datetime(t).hour)\ndf_test['year'] = df_test.pickup_datetime.apply(lambda t: pd.to_datetime(t).year)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c025af2a0f475395bcaf98cae520a82be2cf042d"
      },
      "cell_type": "markdown",
      "source": "# Model\n\nBased on the analysis above, I would start with the following model:"
    },
    {
      "metadata": {
        "_uuid": "d6e8d617975bc9ef861d3217996f4c54776f4f3e"
      },
      "cell_type": "markdown",
      "source": "$$\n\\text{fare} \\text{ ~ } \\text{year}, \\text{hour}, \\text{distance}, \\text{passenger_count}\n$$"
    },
    {
      "metadata": {
        "_uuid": "3b6e7a7d1e485243fbb458764ccab28229625c0e"
      },
      "cell_type": "markdown",
      "source": "For a baseline model I use a linear regression model."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "fabe06b701eff1455f37268724189d29bfcaccb5"
      },
      "cell_type": "code",
      "source": "# define dataset\n# select points 15 miles near NYC center and remove zero passenger datapoints\nidx = (df_train.distance_to_center<15) & (df_train.passenger_count!=0)\nfeatures = ['year', 'hour', 'distance_miles', 'passenger_count']\nX = df_train[idx][features].values\ny = df_train[idx]['fare_amount'].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7b2367e87675e9d15799a8195e3841a98917007"
      },
      "cell_type": "code",
      "source": "X.shape, y.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "7ec943bdefd82059204fcd83132e6fa3542d7584"
      },
      "cell_type": "code",
      "source": "# define some handy analysis support function\nfrom sklearn.metrics import mean_squared_error, explained_variance_score\n\ndef plot_prediction_analysis(y, y_pred, figsize=(10,4), title=''):\n    fig, axs = plt.subplots(1, 2, figsize=figsize)\n    axs[0].scatter(y, y_pred)\n    mn = min(np.min(y), np.min(y_pred))\n    mx = max(np.max(y), np.max(y_pred))\n    axs[0].plot([mn, mx], [mn, mx], c='red')\n    axs[0].set_xlabel('$y$')\n    axs[0].set_ylabel('$\\hat{y}$')\n    rmse = np.sqrt(mean_squared_error(y, y_pred))\n    evs = explained_variance_score(y, y_pred)\n    axs[0].set_title('rmse = {:.2f}, evs = {:.2f}'.format(rmse, evs))\n    \n    axs[1].hist(y-y_pred, bins=50)\n    avg = np.mean(y-y_pred)\n    std = np.std(y-y_pred)\n    axs[1].set_xlabel('$y - \\hat{y}$')\n    axs[1].set_title('Histrogram prediction error, $\\mu$ = {:.2f}, $\\sigma$ = {:.2f}'.format(avg, std))\n    \n    if title!='':\n        fig.suptitle(title)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "fdeac720c4497719c61b10aa5fe256f1bfb5374e"
      },
      "cell_type": "code",
      "source": "# create training and test sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9dd10c933221891047bcaab026abe60ab84072e0"
      },
      "cell_type": "code",
      "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\nmodel_lin = Pipeline((\n        (\"standard_scaler\", StandardScaler()),\n        (\"lin_reg\", LinearRegression()),\n    ))\nmodel_lin.fit(X_train, y_train)\n\ny_train_pred = model_lin.predict(X_train)\nplot_prediction_analysis(y_train, y_train_pred, title='Linear Model - Trainingset')\n\ny_test_pred = model_lin.predict(X_test)\nplot_prediction_analysis(y_test, y_test_pred, title='Linear Model - Testset')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "336016d59c57b493797830434f7e7ce811684b1e"
      },
      "cell_type": "code",
      "source": "# some handy function to see how sensitive the model is to the selection\n# of the training and test set\ndef plot_rmse_analysis(model, X, y, N=400, test_size=0.25, figsize=(10,4), title=''):\n    rmse_train, rmse_test = [], []\n    for i in range(N):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n\n        model.fit(X_train, y_train)\n        y_train_pred = model.predict(X_train)\n        y_test_pred = model.predict(X_test)\n\n        rmse_train.append(np.sqrt(mean_squared_error(y_train, y_train_pred)))\n        rmse_test.append(np.sqrt(mean_squared_error(y_test, y_test_pred)))\n\n    g = sns.jointplot(np.array(rmse_train), np.array(rmse_test), kind='scatter', stat_func=None, size=5)\n    g.set_axis_labels(\"RMSE training ($\\mu$={:.2f})\".format(np.mean(rmse_train)), \n                      \"RMSE test ($\\mu$={:.2f})\".format(np.mean(rmse_test)))\n    plt.subplots_adjust(top=0.9)\n    g.fig.suptitle('{} (N={}, test_size={:0.2f})'.format(title, N, test_size))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "726c456ec6c9f838196726f537386574ff187f9c"
      },
      "cell_type": "code",
      "source": "# only 100k points are used to shorten calculation time\nplot_rmse_analysis(model_lin, X[:100_000,:], y[:100_000], title='Linear model')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "02b7faebfd82ead6a6cc5b879c7ffbb26976007b"
      },
      "cell_type": "markdown",
      "source": "## Generate Kaggle submission\n\nThe code below can be used to generate a Kaggle submission file."
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "12430b1ba2ba1300fbb54096673f5a034e34e117"
      },
      "cell_type": "code",
      "source": "# define dataset\nXTEST = df_test[features].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f831c6cc4f578db8697884182ccf9633cddb6037",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "filename = './output/baseline_linear'\n\ny_pred_final = model_lin.predict(XTEST)\n\nsubmission = pd.DataFrame(\n    {'key': df_test.key, 'fare_amount': y_pred_final},\n    columns = ['key', 'fare_amount'])\nsubmission.to_csv('submission.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "82fd2863824cd05d606cd170e879845271bd91f1"
      },
      "cell_type": "code",
      "source": "submission",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "85c048cb23d197f9fa30703827499673cc6ee534"
      },
      "cell_type": "markdown",
      "source": "This model gives a kaggle score of about 5. Certainly not the best model on the leaderboard, but what could we expect from a linear regression model? \n\nFrom now on we need to improve the model. Considering the analysis above, I would search for a model that is able to:\n\n- model the non-linear time (`hour`) dependency\n- model different pricings (e.g. fixed fee to an airport vs metered ride)\n- model location dependencies and avoid the direct point-to-point distance measure.\n"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "137aeb7c4fecd312c36be57833f0d82357259010"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}